diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 000000000..4928825cd
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,14 @@
+from sklearn import svm
+from sklearn.datasets import samples_generator
+from sklearn.feature_selection import SelectKBest, f_regression
+from sklearn.pipeline import Pipeline
+
+# generate some data to play with
+X, y = samples_generator.make_classification(
+    n_informative=5, n_redundant=0, random_state=42)
+
+anova_filter = SelectKBest(f_regression, k=5)
+clf = svm.SVC(kernel='linear')
+pipe = Pipeline([('anova', anova_filter), ('svc', clf)])
+
+len(pipe)
diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py
index 7eaf9a46f..4d42b6dad 100644
--- a/sklearn/pipeline.py
+++ b/sklearn/pipeline.py
@@ -15,25 +15,34 @@ from itertools import islice
 import numpy as np
 from scipy import sparse
 
-from .base import clone, TransformerMixin
+from collections import defaultdict
+from itertools import islice
+
+import numpy as np
+from scipy import sparse
+
+from .base import clone, TransformerMixin, BaseEstimator, MetaEstimatorMixin  # Add required imports here
 from .utils._joblib import Parallel, delayed
 from .utils.metaestimators import if_delegate_has_method
 from .utils import Bunch
 from .utils.validation import check_memory
 
+from .utils.metaestimators import if_delegate_has_method
+from .utils import Bunch
+from .utils.validation import check_memory
+
 from .utils.metaestimators import _BaseComposition
 
 __all__ = ['Pipeline', 'FeatureUnion', 'make_pipeline', 'make_union']
 
-
-class Pipeline(_BaseComposition):
+class Pipeline(_BaseComposition, BaseEstimator, MetaEstimatorMixin):
     """Pipeline of transforms with a final estimator.
 
     Sequentially apply a list of transforms and a final estimator.
     Intermediate steps of the pipeline must be 'transforms', that is, they
-    must implement fit and transform methods.
-    The final estimator only needs to implement fit.
-    The transformers in the pipeline can be cached using ``memory`` argument.
+    must implement fit and transform methods. The final estimator only needs
+    to implement fit. The transformers in the pipeline can be cached using
+    ``memory`` argument.
 
     The purpose of the pipeline is to assemble several steps that can be
     cross-validated together while setting different parameters.
@@ -43,6 +52,7 @@ class Pipeline(_BaseComposition):
     with its name to another estimator, or a transformer removed by setting
     it to 'passthrough' or ``None``.
 
+
     Read more in the :ref:`User Guide <pipeline>`.
 
     Parameters
@@ -131,6 +141,11 @@ class Pipeline(_BaseComposition):
         self._validate_steps()
         self.memory = memory
 
+    def __len__(self):
+        """Return the number of steps in the pipeline."""
+        return len(self.steps)
+
+
     def get_params(self, deep=True):
         """Get parameters for this estimator.
 
@@ -929,3 +944,6 @@ def make_union(*transformers, **kwargs):
         raise TypeError('Unknown keyword arguments: "{}"'
                         .format(list(kwargs.keys())[0]))
     return FeatureUnion(_name_estimators(transformers), n_jobs=n_jobs)
+
+
+
